{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c9dc26-7d30-4888-8b54-95393bf09d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import beta\n",
    "import pickle\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,mean_squared_error\n",
    "from itertools import combinations\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff762ed-de76-4b39-84f7-f59772fd82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('CSV/Labelled_data.csv')\n",
    "questions={\n",
    "    'EI':[0,2,4,6,8,10,12,14,16],\n",
    "    'WI':[27,30,33,36,38,41,44,47,50],\n",
    "    'EC':[39,32,35,40,43,46,49,52,53],\n",
    "    'WC':[1,5,9,13,17,19,21,23,25],\n",
    "    'EA':[3,7,11,16,18,20,22,24,26],\n",
    "    'WA':[28,31,34,37,39,42,45,48,51],\n",
    "    'AM':[56,60,72],\n",
    "    'LC':[54,59,64,67],\n",
    "    'MC':[55,62,65,69],\n",
    "    'ND':[63,66],\n",
    "    'PfW':[58,68,71],\n",
    "    'SE':[57,61,70,73],\n",
    "    'E':[74,79,84,89,94,99,104,109,114,119],\n",
    "    'A':[75,80,85,90,95,100,105,110,115,120],\n",
    "    'C':[76,81,86,91,96,101,106,111,116,121],\n",
    "    'N':[77,82,87,92,97,102,107,112,117,122],\n",
    "    'O':[78,83,88,93,98,103,108,113,118,123]\n",
    "}\n",
    "def I_label(score):\n",
    "    if(score==6 or score==7):\n",
    "        return 0\n",
    "    if(score>=2 and score <=5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def C_label(score):\n",
    "    if(score>=4 and score<=7):\n",
    "        return 0\n",
    "    elif(score==2 or score==3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def A_label(score):\n",
    "    if(score>=4 and score<=6):\n",
    "        return 0\n",
    "    if(score>=7 and score <=9):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def AM_LC_label(score):\n",
    "    if(score>=4 and score<=5):\n",
    "        return 0\n",
    "    elif(score>=2.6 and score<=3.9):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def rest_label(score):\n",
    "    if(score>=4 and score<=6):\n",
    "        return 0\n",
    "    elif(score>=2.6 and score<=3.9):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def EN_label(score):\n",
    "    if(score>=0 and score<=25):\n",
    "        return 0\n",
    "    elif(score>=26 and score<=40):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def AO_label(score):\n",
    "    if(score>=0 and score<=30):\n",
    "        return 0\n",
    "    elif(score>=31 and score<=40):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def C3_label(score):\n",
    "    if(score>=36 and score<=50):\n",
    "        return 0\n",
    "    elif(score>=26 and score<=35):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def I_smoothing(x):\n",
    "    return(((8-x)*math.exp(0.6*x)+221.406)/29.591)\n",
    "def C_smoothing(x):\n",
    "    return(((12-x)*math.exp(0.15*x)-11.572)/0.327)\n",
    "def A_smoothing(x):\n",
    "    return((2+((x-2)*math.exp(-0.32*x)))/0.261)\n",
    "def identity(x):\n",
    "    return x\n",
    "functions={\n",
    "    'EI':I_label,\n",
    "    'WI':I_label,\n",
    "    'EC':C_label,\n",
    "    'WC':C_label,\n",
    "    'EA':A_label,\n",
    "    'WA':A_label,\n",
    "    'AM':AM_LC_label,\n",
    "    'LC':AM_LC_label,\n",
    "    'MC':rest_label,\n",
    "    'ND':rest_label,\n",
    "    'PfW':rest_label,\n",
    "    'SE':rest_label,\n",
    "    'E':EN_label,\n",
    "    'A':AO_label,\n",
    "    'C':C3_label,\n",
    "    'N':EN_label,\n",
    "    'O':AO_label\n",
    "}\n",
    "smoothing={\n",
    "    'EI':I_smoothing,\n",
    "    'WI':I_smoothing,\n",
    "    'EC':C_smoothing,\n",
    "    'WC':C_smoothing,\n",
    "    'EA':A_smoothing,\n",
    "    'WA':A_smoothing,\n",
    "    'AM':identity,\n",
    "    'LC':identity,\n",
    "    'MC':identity,\n",
    "    'ND':identity,\n",
    "    'PfW':identity,\n",
    "    'SE':identity,\n",
    "    'E':identity,\n",
    "    'A':identity,\n",
    "    'C':identity,\n",
    "    'N':identity,\n",
    "    'O':identity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3bd874-bc16-4c2f-815d-c8788708e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml(X,labels):\n",
    "    split_index = int(0.6*df.shape[0])\n",
    "    labels=np.array(labels)\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = labels[:split_index], labels[split_index:]\n",
    "    logistic_regression_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    logistic_regression_classifier.fit(X_train, y_train)\n",
    "    y_pred = logistic_regression_classifier.predict(X_train)\n",
    "    probabilities = logistic_regression_classifier.predict_proba(X_train)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    logistic_confidence_train=np.mean(confidences)\n",
    "    acc_logistic_train=accuracy_score(y_train, y_pred)\n",
    "    y_pred = logistic_regression_classifier.predict(X_test)\n",
    "    probabilities = logistic_regression_classifier.predict_proba(X_test)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    logistic_confidence=np.mean(confidences)\n",
    "    acc_logistic=accuracy_score(y_test, y_pred)\n",
    "    svm_classifier = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    y_pred = svm_classifier.predict(X_train)\n",
    "    confidence_scores = svm_classifier.decision_function(X_train)\n",
    "    svm_confidence_train=np.mean(np.abs(confidence_scores))\n",
    "    acc_svm_train=accuracy_score(y_train, y_pred)\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    confidence_scores = svm_classifier.decision_function(X_test)\n",
    "    svm_confidence=np.mean(np.abs(confidence_scores))\n",
    "    acc_svm=accuracy_score(y_test, y_pred)\n",
    "    h1=len(X_train[0])\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(2*h1,6), max_iter=500, random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_train)\n",
    "    probabilities = mlp.predict_proba(X_train)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    mlp_confidence_train=np.mean(confidences)\n",
    "    acc_mlp_train=accuracy_score(y_train, y_pred)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    probabilities = mlp.predict_proba(X_test)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    mlp_confidence=np.mean(confidences)\n",
    "    acc_mlp=accuracy_score(y_test, y_pred)\n",
    "    random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    random_forest_classifier.fit(X_train, y_train)\n",
    "    y_pred = random_forest_classifier.predict(X_train)\n",
    "    probabilities = random_forest_classifier.predict_proba(X_train)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    rf_confidence_train=np.mean(confidences)\n",
    "    acc_rf_train=accuracy_score(y_train, y_pred)\n",
    "    y_pred = random_forest_classifier.predict(X_test)\n",
    "    probabilities = random_forest_classifier.predict_proba(X_test)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    rf_confidence=np.mean(confidences)\n",
    "    acc_rf=accuracy_score(y_test, y_pred)\n",
    "    data=[acc_logistic_train,acc_logistic,acc_svm_train,acc_svm,acc_mlp_train,acc_mlp,acc_rf_train,acc_rf]\n",
    "    confidence=[logistic_confidence_train,logistic_confidence,svm_confidence_train,svm_confidence_train, svm_confidence,mlp_confidence_train,mlp_confidence,rf_confidence_train,rf_confidence]\n",
    "    return confidence,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f342c6-bf1c-4d84-8303-2423dc7db23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(trait):\n",
    "    if(trait=='all'):\n",
    "        indices=[i for i in range(124)]\n",
    "        labels=list(df['Final Label'])\n",
    "    else:\n",
    "        indices=questions[trait]\n",
    "        labels=[functions[trait](i) for i in list(df[trait])]\n",
    "    cols=[f'feature{k}' for k in indices]\n",
    "    X=df[cols].values\n",
    "    con,info=ml(X,labels)\n",
    "    print(trait)\n",
    "    print(info)\n",
    "    return con,info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c24109-4973-4111-bccb-ee048dfaf588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBSCHOLOR-2020-18\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EI\n",
      "[0.7697103043637697, 0.8053875755909841, 0.8687202053538687, 0.8576140736668499, 0.8804547121378804, 0.8658603628367235, 0.9955995599559956, 0.8911489829576691]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBSCHOLOR-2020-18\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WI\n",
      "[0.5786578657865786, 0.35843870258383725, 0.9083241657499084, 0.8548653106102254, 0.9094242757609095, 0.8636613523914238, 1.0, 0.9620670698185816]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBSCHOLOR-2020-18\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC\n",
      "[0.7348734873487349, 0.576690489279824, 0.8683535020168683, 0.8647608576140736, 0.8698203153648698, 0.868609125893348, 0.9996332966629996, 0.8933479934029687]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBSCHOLOR-2020-18\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WC\n",
      "[0.6153281994866153, 0.371632765255635, 0.8874220755408874, 0.8510170423309511, 0.8822882288228823, 0.8482682792743266, 1.0, 0.920285871357889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBSCHOLOR-2020-18\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EA\n",
      "[0.8096809680968097, 0.8092358438702584, 0.9086908690869087, 0.8642111050027488, 0.9061239457279061, 0.863111599780099, 1.0, 0.9433754810335349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBSCHOLOR-2020-18\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WA\n",
      "[0.8258159149248259, 0.7910940076965366, 0.9178584525119179, 0.8785046728971962, 0.9196919691969196, 0.8840021990104453, 1.0, 0.9406267179769104]\n",
      "AM\n",
      "[0.9977997799779978, 0.9972512369433755, 0.9988998899889989, 0.9934029686641012, 1.0, 1.0, 1.0, 0.9956019791094007]\n",
      "LC\n",
      "[0.9834983498349835, 0.9928532160527762, 0.9864319765309865, 0.994502473886751, 0.9996332966629996, 0.9972512369433755, 1.0, 0.9917537108301264]\n",
      "MC\n",
      "[0.9981664833149981, 1.0, 0.9904657132379905, 0.9967014843320505, 1.0, 1.0, 1.0, 0.9824079164376031]\n",
      "ND\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "PfW\n",
      "[0.9992665933259993, 0.9967014843320505, 0.9977997799779978, 1.0, 1.0, 1.0, 1.0, 0.9978009895547004]\n",
      "SE\n",
      "[0.9981664833149981, 1.0, 0.991932526585992, 0.9972512369433755, 1.0, 1.0, 1.0, 0.9747113798790544]\n",
      "E\n",
      "[1.0, 1.0, 0.9933993399339934, 0.9901044529961517, 1.0, 0.9989004947773502, 1.0, 0.9582188015393073]\n",
      "A\n",
      "[1.0, 0.9983507421660253, 0.9933993399339934, 0.9906542056074766, 1.0, 0.9967014843320505, 0.9996332966629996, 0.9741616272677295]\n",
      "C\n",
      "[0.9992665933259993, 1.0, 0.9886321965529886, 0.9884551951621771, 1.0, 1.0, 1.0, 0.9444749862561848]\n",
      "N\n",
      "[1.0, 1.0, 0.9955995599559956, 0.9939527212754261, 1.0, 1.0, 1.0, 0.9664650907091809]\n",
      "O\n",
      "[1.0, 1.0, 0.9970663733039971, 0.9978009895547004, 1.0, 0.9972512369433755, 1.0, 0.9868059373282023]\n",
      "all\n",
      "[0.7708104143747708, 0.622869708631116, 0.8155482214888156, 0.6503573391973612, 1.0, 0.6415612974161627, 1.0, 0.6723474436503574]\n",
      "Accuracy\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|   Logistic-Train |   Logistic-Test |   SVM-Train |   SVM-Test |   MLP-Train |   MLP-Test |   Random Forest-Train |   Random Forest-Test |\n",
      "+==================+=================+=============+============+=============+============+=======================+======================+\n",
      "|         0.76971  |        0.805388 |    0.86872  |   0.857614 |    0.880455 |   0.86586  |              0.9956   |             0.891149 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.578658 |        0.358439 |    0.908324 |   0.854865 |    0.909424 |   0.863661 |              1        |             0.962067 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.734873 |        0.57669  |    0.868354 |   0.864761 |    0.86982  |   0.868609 |              0.999633 |             0.893348 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.615328 |        0.371633 |    0.887422 |   0.851017 |    0.882288 |   0.848268 |              1        |             0.920286 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.809681 |        0.809236 |    0.908691 |   0.864211 |    0.906124 |   0.863112 |              1        |             0.943375 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.825816 |        0.791094 |    0.917858 |   0.878505 |    0.919692 |   0.884002 |              1        |             0.940627 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.9978   |        0.997251 |    0.9989   |   0.993403 |    1        |   1        |              1        |             0.995602 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.983498 |        0.992853 |    0.986432 |   0.994502 |    0.999633 |   0.997251 |              1        |             0.991754 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.998166 |        1        |    0.990466 |   0.996701 |    1        |   1        |              1        |             0.982408 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         1        |        1        |    1        |   1        |    1        |   1        |              1        |             1        |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.999267 |        0.996701 |    0.9978   |   1        |    1        |   1        |              1        |             0.997801 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.998166 |        1        |    0.991933 |   0.997251 |    1        |   1        |              1        |             0.974711 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         1        |        1        |    0.993399 |   0.990104 |    1        |   0.9989   |              1        |             0.958219 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         1        |        0.998351 |    0.993399 |   0.990654 |    1        |   0.996701 |              0.999633 |             0.974162 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.999267 |        1        |    0.988632 |   0.988455 |    1        |   1        |              1        |             0.944475 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         1        |        1        |    0.9956   |   0.993953 |    1        |   1        |              1        |             0.966465 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         1        |        1        |    0.997066 |   0.997801 |    1        |   0.997251 |              1        |             0.986806 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|         0.77081  |        0.62287  |    0.815548 |   0.650357 |    1        |   0.641561 |              1        |             0.672347 |\n",
      "+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "Confidence\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "|          |   Logistic-Train |   Logistic-Test |   SVM-Train |   SVM-Test |   MLP-Train |   MLP-Test |   Random Forest-Train |   Random Forest-Test |\n",
      "+==========+==================+=================+=============+============+=============+============+=======================+======================+\n",
      "| 0.700542 |         0.701447 |         1.16642 |     1.16642 |    1.1776  |    0.869721 |   0.892207 |              0.930458 |             0.874287 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.576884 |         0.568363 |         1.16892 |     1.16892 |    1.19362 |    0.903306 |   0.896006 |              0.956443 |             0.886822 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.718228 |         0.676866 |         1.15133 |     1.15133 |    1.15672 |    0.866353 |   0.875814 |              0.930129 |             0.854882 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.584687 |         0.581911 |         1.16618 |     1.16618 |    1.15563 |    0.880065 |   0.905609 |              0.945919 |             0.892963 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.810865 |         0.787225 |         1.19137 |     1.19137 |    1.2013  |    0.896636 |   0.887711 |              0.952208 |             0.904689 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.814136 |         0.780529 |         1.17694 |     1.17694 |    1.17376 |    0.916365 |   0.936818 |              0.953751 |             0.916548 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.934747 |         0.959623 |         1.16702 |     1.16702 |    1.15426 |    0.994306 |   0.996888 |              0.997404 |             0.992925 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.956341 |         0.983505 |         1.16682 |     1.16682 |    1.15305 |    0.993404 |   0.996552 |              0.990862 |             0.98624  |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.891795 |         0.906217 |         1.16795 |     1.16795 |    1.17464 |    0.993715 |   0.995152 |              0.985534 |             0.969428 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.893651 |         0.902973 |         1.18512 |     1.18512 |    1.18503 |    0.994151 |   0.994844 |              0.999883 |             1        |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.908659 |         0.890757 |         1.16635 |     1.16635 |    1.16614 |    0.993084 |   0.991567 |              0.995926 |             0.990583 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.889509 |         0.901527 |         1.1799  |     1.1799  |    1.18452 |    0.994073 |   0.994803 |              0.984686 |             0.964557 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.964837 |         0.980569 |         2.70729 |     2.70729 |    3.28683 |    0.995661 |   0.99566  |              0.955636 |             0.934997 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.965914 |         0.985056 |         2.91122 |     2.91122 |    3.42043 |    0.99566  |   0.995526 |              0.967477 |             0.949285 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.934964 |         0.943547 |         1.19974 |     1.19974 |    1.20978 |    0.996116 |   0.995844 |              0.94516  |             0.875531 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.961696 |         0.978928 |         3.08829 |     3.08829 |    3.52265 |    0.997271 |   0.997619 |              0.951823 |             0.928125 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.968761 |         0.987295 |         2.8491  |     2.8491  |    3.30436 |    0.994706 |   0.99713  |              0.97278  |             0.966767 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n",
      "| 0.775051 |         0.791963 |         1.13923 |     1.13923 |    1.14315 |    0.998658 |   0.939042 |              0.868295 |             0.741468 |\n",
      "+----------+------------------+-----------------+-------------+------------+-------------+------------+-----------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "traits=['EI','WI','EC','WC','EA','WA','AM','LC','MC','ND','PfW','SE','E','A','C','N','O','all']\n",
    "data=[]\n",
    "confidence=[]\n",
    "headers=['Logistic-Train','Logistic-Test','SVM-Train','SVM-Test','MLP-Train','MLP-Test','Random Forest-Train','Random Forest-Test']\n",
    "for trait in traits:\n",
    "    con,info=get_results(trait)\n",
    "    data.append(info)\n",
    "    confidence.append(con)\n",
    "print(\"Accuracy\")\n",
    "print(tabulate(data, headers=headers, tablefmt=\"grid\"))\n",
    "print(\"Confidence\")\n",
    "print(tabulate(confidence, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5d22c-37b2-4548-98eb-ea3ea13f1aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
