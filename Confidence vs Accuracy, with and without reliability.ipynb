{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41b260e-d665-4033-956b-00ed379db466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import beta\n",
    "import pickle\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,mean_squared_error\n",
    "from itertools import combinations\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94c0cdb-c7e6-48b4-81ff-0d623ba4f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_sets={\n",
    "    'EI':[[2,4],[0,10],[6,15]],\n",
    "    'WI':[[30,33,38,44,47,50]],\n",
    "    'EC':[[29,46],[32,49,53],[35,52]],\n",
    "    'WC':[[1,17],[5,21,25],[9,23]],\n",
    "    'EA':[[3,7,20,26],[11,22],[18,24]],\n",
    "    'WA':[[34,39,45,51],[31,42,28]],\n",
    "    'E':[[79,99]],\n",
    "    'A':[[80,105]],\n",
    "    'N':[[92,122]],\n",
    "    'O':[[88,103],[98,123]]\n",
    "}\n",
    "traits=['EI','WI','EC','WC','EA','WA','E','A','N','O']\n",
    "df=pd.read_csv('CSV/Labelled_data.csv')\n",
    "questions={\n",
    "    'EI':[0,2,4,6,8,10,12,14,16],\n",
    "    'WI':[27,30,33,36,38,41,44,47,50],\n",
    "    'EC':[39,32,35,40,43,46,49,52,53],\n",
    "    'WC':[1,5,9,13,17,19,21,23,25],\n",
    "    'EA':[3,7,11,16,18,20,22,24,26],\n",
    "    'WA':[28,31,34,37,39,42,45,48,51],\n",
    "    'AM':[56,60,72],\n",
    "    'LC':[54,59,64,67],\n",
    "    'MC':[55,62,65,69],\n",
    "    'ND':[63,66],\n",
    "    'PfW':[58,68,71],\n",
    "    'SE':[57,61,70,73],\n",
    "    'E':[74,79,84,89,94,99,104,109,114,119],\n",
    "    'A':[75,80,85,90,95,100,105,110,115,120],\n",
    "    'C':[76,81,86,91,96,101,106,111,116,121],\n",
    "    'N':[77,82,87,92,97,102,107,112,117,122],\n",
    "    'O':[78,83,88,93,98,103,108,113,118,123]\n",
    "}\n",
    "def I_label(score):\n",
    "    if(score==6 or score==7):\n",
    "        return 0\n",
    "    if(score>=2 and score <=5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def C_label(score):\n",
    "    if(score>=4 and score<=7):\n",
    "        return 0\n",
    "    elif(score==2 or score==3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def A_label(score):\n",
    "    if(score>=4 and score<=6):\n",
    "        return 0\n",
    "    if(score>=7 and score <=9):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def AM_LC_label(score):\n",
    "    if(score>=4 and score<=5):\n",
    "        return 0\n",
    "    elif(score>=2.6 and score<=3.9):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def rest_label(score):\n",
    "    if(score>=4 and score<=6):\n",
    "        return 0\n",
    "    elif(score>=2.6 and score<=3.9):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def EN_label(score):\n",
    "    if(score>=0 and score<=25):\n",
    "        return 0\n",
    "    elif(score>=26 and score<=40):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def AO_label(score):\n",
    "    if(score>=0 and score<=30):\n",
    "        return 0\n",
    "    elif(score>=31 and score<=40):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def C3_label(score):\n",
    "    if(score>=36 and score<=50):\n",
    "        return 0\n",
    "    elif(score>=26 and score<=35):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def I_smoothing(x):\n",
    "    return(((8-x)*math.exp(0.6*x)+221.406)/29.591)\n",
    "def C_smoothing(x):\n",
    "    return(((12-x)*math.exp(0.15*x)-11.572)/0.327)\n",
    "def A_smoothing(x):\n",
    "    return((2+((x-2)*math.exp(-0.32*x)))/0.261)\n",
    "def identity(x):\n",
    "    return x\n",
    "functions={\n",
    "    'EI':I_label,\n",
    "    'WI':I_label,\n",
    "    'EC':C_label,\n",
    "    'WC':C_label,\n",
    "    'EA':A_label,\n",
    "    'WA':A_label,\n",
    "    'AM':AM_LC_label,\n",
    "    'LC':AM_LC_label,\n",
    "    'MC':rest_label,\n",
    "    'ND':rest_label,\n",
    "    'PfW':rest_label,\n",
    "    'SE':rest_label,\n",
    "    'E':EN_label,\n",
    "    'A':AO_label,\n",
    "    'C':C3_label,\n",
    "    'N':EN_label,\n",
    "    'O':AO_label\n",
    "}\n",
    "smoothing={\n",
    "    'EI':I_smoothing,\n",
    "    'WI':I_smoothing,\n",
    "    'EC':C_smoothing,\n",
    "    'WC':C_smoothing,\n",
    "    'EA':A_smoothing,\n",
    "    'WA':A_smoothing,\n",
    "    'AM':identity,\n",
    "    'LC':identity,\n",
    "    'MC':identity,\n",
    "    'ND':identity,\n",
    "    'PfW':identity,\n",
    "    'SE':identity,\n",
    "    'E':identity,\n",
    "    'A':identity,\n",
    "    'C':identity,\n",
    "    'N':identity,\n",
    "    'O':identity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad5dab7-2c91-46ec-afdb-2081fd857cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml(X,labels):\n",
    "    split_index = int(0.6 * df.shape[0])\n",
    "    labels=np.array(labels)\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = labels[:split_index], labels[split_index:]\n",
    "    logistic_regression_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    logistic_regression_classifier.fit(X_train, y_train)\n",
    "    y_pred = logistic_regression_classifier.predict(X_test)\n",
    "    probabilities = logistic_regression_classifier.predict_proba(X_test)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    logistic_confidence=np.mean(confidences)\n",
    "    acc_logistic=accuracy_score(y_test, y_pred)\n",
    "    svm_classifier = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    confidence_scores = svm_classifier.decision_function(X_test)\n",
    "    svm_confidence=np.mean(np.abs(confidence_scores))\n",
    "    acc_svm=accuracy_score(y_test, y_pred)\n",
    "    h1=len(X_train[0])\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(2*h1,6), max_iter=500, random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    probabilities = mlp.predict_proba(X_test)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    mlp_confidence=np.mean(confidences)\n",
    "    acc_mlp=accuracy_score(y_test, y_pred)\n",
    "    random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    random_forest_classifier.fit(X_train, y_train)\n",
    "    y_pred = random_forest_classifier.predict(X_test)\n",
    "    probabilities = random_forest_classifier.predict_proba(X_test)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    rf_confidence=np.mean(confidences)\n",
    "    acc_rf=accuracy_score(y_test, y_pred)\n",
    "    data=[acc_logistic,acc_svm,acc_mlp,acc_rf]\n",
    "    confidence=[logistic_confidence,svm_confidence,mlp_confidence,rf_confidence]\n",
    "    return confidence,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31dbd6c-6085-4cdd-8edd-1ca5e02d8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliability(trait):\n",
    "    l=df.shape[0]\n",
    "    subsets=similar_sets[trait]\n",
    "    scores=[]\n",
    "    dissimilar=[(80,105),(92,122),(88,103),(105,80),(122,92),(103,88)]\n",
    "    for ques in subsets:\n",
    "        n=len(ques)\n",
    "        r=np.zeros(1)\n",
    "        s=np.zeros(l)\n",
    "        cnt=0\n",
    "        for i in range(n):\n",
    "            for j in range(i+1,n):\n",
    "                cnt+=1\n",
    "                x1=np.array(list(df[f'feature{ques[i]}']))\n",
    "                x2=np.array(list(df[f'feature{ques[j]}']))\n",
    "                if((ques[i],ques[j]) in dissimilar):\n",
    "                    r=np.abs(x1+x2)\n",
    "                else:\n",
    "                    r=np.abs(x1-x2)\n",
    "                for k in range(l):\n",
    "                    s[k]+=1-r[k]/np.max(r)\n",
    "        for k in range(l):\n",
    "            s[k]=s[k]/cnt\n",
    "        scores.append(s)\n",
    "    scores=np.array(scores)\n",
    "    scores=np.transpose(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "764ed00e-5198-423a-972e-e3d34adbf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scr=None by default whecn no reliability vector is passed, otherwise the vector is appended to the \n",
    "# existing feature set\n",
    "def correlation_algo(trait,scr=None):\n",
    "    truncate_index = int(len(df) * 0.6)\n",
    "    truncated_df = df.iloc[:]\n",
    "    indices=questions[trait]\n",
    "    f=len(indices)\n",
    "    y=[functions[trait](i) for i in list(truncated_df[trait])]\n",
    "    values=[smoothing[trait](i) for i in list(truncated_df[trait])]\n",
    "    X=[]\n",
    "    for i in indices:\n",
    "        X.append(list(truncated_df[f'feature{i}']))\n",
    "    l=len(X[0])\n",
    "    corr_matrix=np.zeros((f,3))\n",
    "    weight_matrix=np.zeros((f,3))\n",
    "    for i in range(3):\n",
    "        c=[values[j] for j in range(l) if y[j]==i]\n",
    "        if(len(c)>0):\n",
    "            for j in range(f):\n",
    "                x_temp=[X[j][k] for k in range(l) if y[k]==i]\n",
    "                corr, _ = pearsonr(x_temp, c)\n",
    "                corr_matrix[j][i]=abs(corr)\n",
    "            x=list(corr_matrix[:,i])\n",
    "            rank_indices=np.argsort(x)\n",
    "            rank=1\n",
    "            for idx in rank_indices:\n",
    "                weight_matrix[idx][i]=rank\n",
    "                rank=rank+1\n",
    "    correlation=np.zeros((f,f))\n",
    "    for i in range(f):\n",
    "        for j in range(f):\n",
    "            x1=X[i][:]\n",
    "            x2=X[j][:]\n",
    "            corr, _ = pearsonr(x1,x2)\n",
    "            correlation[i][j]=corr\n",
    "    scores=[]\n",
    "    for i in range(f):\n",
    "        weight_sum=0\n",
    "        corr_sum=0\n",
    "        for j in range(3):\n",
    "            corr_sum=corr_sum+(corr_matrix[i][j]*weight_matrix[i][j])\n",
    "            weight_sum=weight_sum+weight_matrix[i][j]\n",
    "        scores.append((corr_sum*f)/(weight_sum*np.sum(correlation[i])))\n",
    "    rank_features=np.argsort(scores)\n",
    "    data=[]\n",
    "    confidence=[]\n",
    "    labels=[functions[trait](i) for i in list(df[trait])]\n",
    "    l=len(scores)-1\n",
    "    correct_order=[]\n",
    "    for i in range(f):\n",
    "        correct_order.append(indices[rank_features[l]])\n",
    "        l=l-1\n",
    "    print(correct_order)\n",
    "    for i in range(1,f):\n",
    "        refined_set=correct_order[:i]\n",
    "        discarded_set=correct_order[i:]\n",
    "        # print(f'Refined set :{refined_set}, Discarded set:{discarded_set}')\n",
    "        X1=[]\n",
    "        for j in range(df.shape[0]):\n",
    "            x=[]\n",
    "            for k in refined_set:\n",
    "                x.append(list(df[f'feature{k}'])[j])\n",
    "            X1.append(x)\n",
    "        X1=np.array(X1)\n",
    "        if(not (scr is None)):\n",
    "            X1=np.concatenate((X1,scr),axis=1)\n",
    "        con,info=ml(X1,labels)\n",
    "        # print(max(info))\n",
    "        data.append(info)\n",
    "        confidence.append(con)\n",
    "    return confidence,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de49fde4-9010-4148-9e8a-8afcd15e9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_reductions_without_reliability(trait):\n",
    "    headers=['Logistic','SVM','MLP','Random Forest']\n",
    "    # scores=reliability(trait)\n",
    "    indices=questions[trait]\n",
    "    f=len(indices)\n",
    "    labels=[functions[trait](i) for i in list(df[trait])]\n",
    "    l=len(labels)\n",
    "    confidence,data=correlation_algo(trait,None)\n",
    "    X=[]\n",
    "    for i in range(l):\n",
    "        x=[]\n",
    "        for j in indices:\n",
    "            x.append(list(df[f'feature{j}'])[i])\n",
    "        X.append(x)\n",
    "    con,info=ml(X,labels)\n",
    "    data.append(info)\n",
    "    confidence.append(con)\n",
    "    print(f'Before reduction Accuracy={max(info)}')\n",
    "    print(tabulate(data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(f'Before reduction Confidence={max(con)}')\n",
    "    print(tabulate(confidence, headers=headers, tablefmt=\"grid\"))\n",
    "    file_path1=f'trait-wise/without_reliability/{trait}_accuracy.pkl'\n",
    "    file_path2=f'trait-wise/without_reliability/{trait}_confidence.pkl'\n",
    "    with open(file_path1,'wb') as f:\n",
    "        pickle.dump(data,f)\n",
    "    with open(file_path2,'wb') as f:\n",
    "        pickle.dump(confidence,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c078305-ae83-4cc9-bc0f-5489f46a234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('EI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c30c65-4065-440d-8de0-8e81d121ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('WI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28a559-6e14-4a3a-a351-39de8cf2b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('EC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec857b-2a88-49f7-b032-5dd0c4107778",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('WC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcaffd-9fc3-47e0-a67b-3c48765d1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('EA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92544bfc-ad49-4535-8926-6269d37f3c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('WA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f1f59-e064-4b3b-8c7f-69bace068ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f422f9be-e9a6-4a06-9c10-b7375a09d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 75, 120, 115, 90, 105, 110, 85, 95, 100]\n",
      "Before reduction Accuracy=0.9983507421660253\n",
      "+------------+----------+----------+-----------------+\n",
      "|   Logistic |      SVM |      MLP |   Random Forest |\n",
      "+============+==========+==========+=================+\n",
      "|   0.909841 | 0.909841 | 0.909841 |        0.909841 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.926883 | 0.926883 | 0.926883 |        0.926883 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.904343 | 0.776251 | 0.77735  |        0.77845  |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.803738 | 0.804288 | 0.79934  |        0.798791 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.814733 | 0.816383 | 0.803738 |        0.773502 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.957669 | 0.95657  | 0.95547  |        0.936778 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.95547  | 0.958769 | 0.951622 |        0.939527 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.968664 | 0.967565 | 0.965366 |        0.959868 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.973612 | 0.976361 | 0.975811 |        0.965915 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.998351 | 0.990654 | 0.996701 |        0.974162 |\n",
      "+------------+----------+----------+-----------------+\n",
      "Before reduction Confidence=3.420433759712307\n",
      "+------------+----------+----------+-----------------+\n",
      "|   Logistic |      SVM |      MLP |   Random Forest |\n",
      "+============+==========+==========+=================+\n",
      "|   0.765061 | 1        | 0.766595 |        0.768928 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.773545 | 0.997022 | 0.77856  |        0.787678 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.800244 | 0.939097 | 0.80454  |        0.810047 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.836854 | 1.01723  | 0.84199  |        0.853413 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.865111 | 1.20992  | 0.863265 |        0.884868 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.923718 | 1.73905  | 0.922934 |        0.91826  |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.923153 | 1.95766  | 0.923194 |        0.916507 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.95658  | 2.14983  | 0.959334 |        0.944423 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.973733 | 2.73777  | 0.976953 |        0.954973 |\n",
      "+------------+----------+----------+-----------------+\n",
      "|   0.985056 | 3.42043  | 0.995526 |        0.949285 |\n",
      "+------------+----------+----------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "call_reductions_without_reliability('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a67c43-6aaf-42a2-9f80-05082441cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fd22f-0086-45df-8bd5-62a224314f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d2d2e-5632-4463-9ca8-30c8a40512cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions_without_reliability('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fada1-6d4f-4e31-a0cf-7158e13909ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_reductions(trait):\n",
    "    headers=['Logistic','SVM','MLP','Random Forest']\n",
    "    scores=reliability(trait)\n",
    "    indices=questions[trait]\n",
    "    f=len(indices)\n",
    "    labels=[functions[trait](i) for i in list(df[trait])]\n",
    "    l=len(labels)\n",
    "    confidence,data=correlation_algo(trait,scores)\n",
    "    X=[]\n",
    "    for i in range(l):\n",
    "        x=[]\n",
    "        for j in indices:\n",
    "            x.append(list(df[f'feature{j}'])[i])\n",
    "        X.append(x)\n",
    "    X=np.concatenate((X,scores),axis=1)\n",
    "    con,info=ml(X,labels)\n",
    "    data.append(info)\n",
    "    confidence.append(con)\n",
    "    print(f'Before reduction Accuracy={max(info)}')\n",
    "    print(tabulate(data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(f'Before reduction Confidence={max(con)}')\n",
    "    print(tabulate(confidence, headers=headers, tablefmt=\"grid\"))\n",
    "    file_path1=f'trait-wise/with_reliability/reliability_{trait}_accuracy.pkl'\n",
    "    file_path2=f'trait-wise/with_reliability/reliability_{trait}_confidence.pkl'\n",
    "    with open(file_path1,'wb') as f:\n",
    "        pickle.dump(data,f)\n",
    "    with open(file_path2,'wb') as f:\n",
    "        pickle.dump(confidence,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc6b9e-c91c-49d3-a506-582cc2714af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('EI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081b792-3649-4f09-9658-fdf4a8d7a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('WI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4af9e-e755-4395-b2bf-6994b60d698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('EC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9ea3f-cba2-4fbd-b10f-0b3b889673fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('WC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43bd53c-cdb0-46c5-a239-76c8415fb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('EA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d8d13-50a8-4902-8271-dd9d2ab908fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('WA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc1de4-48d9-4a6e-9fd4-ebe15e834362",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47f9bb-1922-4b57-9eb6-3c3417ffdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55406f62-d3f0-401b-abae-7c4f0b89721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f939f-4047-439c-b4fc-1700bfe3cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reductions('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb964d-7eec-4d41-95fe-119159b24488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
